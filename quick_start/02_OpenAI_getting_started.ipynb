{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# OpenAI Quickstart"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Overview  \n",
        ">\"Large Language Model(LLM)은 텍스트를 텍스트에 매핑하는 기능입니다. 입력 문자열이 주어지면 LLM은 다음에 나올 텍스트를 예측하려고 합니다\"(1). 이 \"QuickStart\" 노트북은 사용자에게 고급 LLM 개념, AML을 시작하기 위한 핵심 패키지 요구 사항, 프롬프트 디자인에 대한 간략한 소개 및 다양한 사용 사례에 대한 몇 가지 간단한 예를 소개합니다.\n",
        "\n",
        "더 많은 빠른 시작 예제를 보려면 [공식 Azure Open AI 빠른 시작 설명서](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio)를 참조하세요.\n",
        "\n",
        ">해당 컨텐츠는 DevContainer 기반으로 개발에 필요한 환경설정이 정의되어져 있습니다. GitHub Codespace를 활용하거나, 로컬에 Docker를 설치한 상태에서 Visual Stduio Code IDE에 해당 Repository를 다운로드 받을 경우, 자동으로 컨테이너에 개발환경(Python Runtime 3.11.4, Azure OpenAI 1.13.3)을 설치합니다. .env 파일에 필수 API 정보를 입력하고 저장후 사용하세요."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Table of Contents  \n",
        "\n",
        "[Overview](#overview)  \n",
        "[How to use OpenAI Service](#how-to-use-openai-service)  \n",
        "[1. Creating your OpenAI Service](#1.-creating-your-openai-service)  \n",
        "[2. Installation](#2.-installation)    \n",
        "[3. Credentials](#3.-credentials)  \n",
        "\n",
        "[Use Cases](#use-cases)    \n",
        "[1. Summarize Text](#1.-summarize-text)  \n",
        "[2. Classify Text](#2.-classify-text)  \n",
        "[3. Generate New Product Names](#3.-generate-new-product-names)  \n",
        "[4. Fine Tune a Classifier](#4.fine-tune-a-classifier)  \n",
        "[5. Embeddings!]((#5.-embeddings!))\n",
        "\n",
        "[References](#references)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Getting started with Azure OpenAI Service\n",
        "\n",
        "신규 고객은 Azure OpenAi 서비스에 [액세스 신청](https://aka.ms/oai/access)을 해야합니다.\n",
        "승인이 완료된 후 고객은 Azure Portal에 로그인하고 Azure OpenAI 서비스 리소스를 만들고 스튜디오를 통해 모델 실험을 시작할 수 있습니다.\n",
        "\n",
        "[Great resource for getting started quickly](https://techcommunity.microsoft.com/t5/educator-developer-blog/azure-openai-is-now-generally-available/ba-p/3719177 )\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Build your first prompt  \n",
        "이 짧은 연습은 간단한 작업 \"요약\"을 위해 OpenAI 모델에 프롬프트를 제출하기위한 기본 소개를 제공합니다.\n",
        "\n",
        "![](images/generative-AI-models-reduced.jpg)  \n",
        "\n",
        "\n",
        "**Steps**:  \n",
        "1. 파이썬 환경에 OpenAI 라이브러리를 설치\n",
        "2. 표준 헬퍼 라이브러리를 로드하고 OpenAI 보안 자격 증명을 설정\n",
        "3. OpenAI 작업에 적합한 모델을 선택\n",
        "4. 모델에 대한 간단한 프롬프트를 만듭니다.\n",
        "5. 모델 API에 요청을 제출하십시오!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 파이썬 환경에 OpenAI 라이브러리를 설치하십시오.\n",
        "DevContainer 가 시작할 때, 자동으로 `requirements.txt` 에 기술한 라이브러리를 설치합니다.\n",
        "따라서 추가적으로 라이브러리 설치를 진행하지 않아도 즉시 실습할 수 있습니다.\n",
        "Python 버전은 **Python 3.11.4**, **Azure OpenAI 1.13.3** 를 사용합니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 2. 표준 헬퍼 라이브러리를 로드하고 OpenAI 보안 자격 증명을 설정\n",
        "루트 디렉토리에 존재하는 .evn.sample 파일을 복사하여 .env 파일을 생성하고 Azure OpenAI Endpoint URL(AZURE_OPENAI_ENDPOINT) 및 API Key(AZURE_OPENAI_API_KEY)를 넣습니다.  \n",
        "만약 하단 코드가 정상적으로 수행되지 않을 경우, 해당 파일을 저장 후 파일을 닫은 후 새로 열어서 진행합니다. (커널 다시 시작을 해도 됩니다. 상단의 `재시작` 버튼 클릭)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1674829434433
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    api_key        = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
        "    api_version    = os.getenv(\"OPENAI_API_VERSION\")\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 3. 작업에 적합한 OpenAI 모델 선택\n",
        "gpt-35-turbo / gpt-4 또는 text-embedding-ada-002 와 같은 OpenAI 모델을 선택합니다.  \n",
        "  \n",
        "2024년 3월 기준, 본 실습에서 사용하는 LLM 모델은 아래와 같이 크게 3종류로 나뉘어집니다.  \n",
        "\n",
        "* gpt-35-turbo / gpt-35-turbo-16k\n",
        "* gpt-4-turbo / gpt-4 / gpt-4-32k\n",
        "* text-embedding-ada-002 / text-embedding-3-small / text-embedding-3-large\n",
        "\n",
        "주로 gpt-35-turbo 모델을 활용합니다. 한글의 토큰 길이에 대한 제약이 있을 경우에 gpt-35-turbo-16k 모델을 활용할 수 있습니다. (gpt-35-turbo-0125 버전은 16K 까지 프롬프트를 활용할 수 있습니다.) \n",
        "좀 더 복합한 작업을 처리할 때에는 gpt-4-turbo 모델이 유용할 수 있습니다.  \n",
        "  \n",
        "모델에 자세한 정보는 다음을 참고하세요: [Azure OpenAI models](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1674742720788
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Select the General Purpose gpt-35-turbo model for text\n",
        "# deployment_name = os.getenv(\"DEPLOYMENT_NAME\")\n",
        "deployment_name = \"gpt-35-turbo\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 4. Prompt Design  \n",
        "\n",
        "대형 언어 모델(LLM)의 마법은 방대한 양의 텍스트 예측 오류를 최소화 하도록 훈련함으로써 모델이 결국 유용하게 예측하도록 개념을 학습하는 것입니다.  \n",
        "예를 들어 다음과 같은 개념을 학습합니다.(1):\n",
        "\n",
        "* 어떻게 쓰는지\n",
        "* 문법의 작동 방식\n",
        "* 의역하는 방법\n",
        "* 질문에 대답하는 방법\n",
        "* 대화를 이끄는 방법\n",
        "* 여러 언어로 작성하는 방법\n",
        "* 코딩하는 방법\n",
        "* 기타\n",
        "\n",
        "### 대형 언어 모델(LLM)을 제어하는 방법  \n",
        "LLM에 대한 모든 입력 중에서 가장 영향력 있는 것은 **텍스트 프롬프트** 입니다.\n",
        "\n",
        "대규모 언어 모델은 몇 가지 방법으로 출력을 생성하라는 메시지를 표시할 수 있습니다: \n",
        "\n",
        "* 지침(Instruction): 모델에게 원하는 것을 말하십시오.\n",
        "* 완료(Completion): 모델이 원하는 것의 시작을 끝낼수 있도록 유도하십시오.\n",
        "* 시연(Demonstration): 다음 중 하나를 사용하여 원하는 것을 모델에 보여주십시오.  \n",
        "프롬프트 내에 몇 가지 예시를 주거나, 또는 수백 또는 수천 개의 예로 구성된 훈련 데이터 세트를 이용한 미세 조정\n",
        "\n",
        "\n",
        "#### 프롬프트를 만들기 위한 세 가지 기본 지침\n",
        "\n",
        "* **Show and tell**: 지침이나 예시 또는 두 가지 조합을 통해 원하는 것을 명확히 하십시오. 모델이 알파벳 순서로 항목 목록을 순위에 올리거나 정서적으로 단락을 분류하려면 원하는 것임을 보여주십시오.\n",
        "\n",
        "* **Provide quality data**: 분류기를 구축하거나 모델이 패턴을 따를 경우 충분한 예시가 있는지 확인하십시오. 예제를 교정하십시오. 모델은 일반적으로 기본 철자 실수를 통해 보고 응답을 제공 할 수있을 정도로 똑똑하지만 의도적이며 응답에 영향을 줄 수 있다고 가정 할 수도 있습니다.\n",
        "\n",
        "* **Check your setting**: 온도(Temperature) 및 TOP_P 설정은 모델이 응답을 생성하는 데 결정적인 방법을 제어합니다. 정답이 하나만 있는 응답을 요청하는 경우 온도를 더 낮게 설정하고 싶을 것입니다. 더 다양한 응답을 찾고 있다면 더 높은 응답을 원할 수도 있습니다. 사람들이 이러한 설정에서 사용하는 가장 큰 실수는 그들이 \"영리\" 또는 \"창의성\" 컨트롤을 가정합니다.  \n",
        "\n",
        "> Source: https://github.com/Azure/OpenAI/blob/main/How%20to/Completions.md"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 5. Submit!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1674494935186
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create your first prompt\n",
        "text_prompt = \"Should oxford commas always be used?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1674494938225
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The use of Oxford commas (also known as serial commas) is a matter of style and preference. Some style guides, such as the AP Stylebook, do not require the use of Oxford commas. However, other style guides, like the Chicago Manual of Style, recommend using them for clarity in lists'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Simple API Call\n",
        "response = client.chat.completions.create(\n",
        "    model=deployment_name,\n",
        "    max_tokens=60,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": text_prompt},\n",
        "    ]\n",
        ")\n",
        "\n",
        "response.choices[0].message.content\n",
        "# print(json.dumps(response.model_dump(), indent=2))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 동일한 호출을 반복합니다. 결과는 어떻게 비교됩니까?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1674494940872
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The use of Oxford commas is a matter of style preference. Some style guides, such as the AP Stylebook, do not require the use of Oxford commas, while others, such as The Chicago Manual of Style, recommend using them for clarity. It's important to be consistent in your use of commas\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Simple API Call\n",
        "response = client.chat.completions.create(\n",
        "    model=deployment_name,\n",
        "    max_tokens=60,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": text_prompt},\n",
        "    ]\n",
        ")\n",
        "\n",
        "response.choices[0].message.content\n",
        "# print(json.dumps(response.model_dump(), indent=2))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Exercises for several use cases  \n",
        "1. Summarize Text  \n",
        "2. Classify Text  \n",
        "3. Generate New Product Names\n",
        "4. Embeddings\n",
        "5. Fine tune a classifier"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Summarize Text  \n",
        "LLM은 다양한 케이스에서 사용이 가능합니다. 요약하기 위한 방법은 다음과 같습니다.\n",
        "결과물에 대한 확인 방법:\n",
        "1. 토크나이저: https://platform.openai.com/tokenizer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1674495198534
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1674495201868
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaling up language models improves few-shot NLP task performance, approaching state-of-the-art fine-tuning methods.\n"
          ]
        }
      ],
      "source": [
        "#Setting a few additional, typical parameters during API Call\n",
        "response = client.chat.completions.create(\n",
        "  model=deployment_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a summarise assistant. Summarizing text length is exactly 20 tokens.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt},\n",
        "  ],\n",
        "  temperature=0.7,\n",
        "  max_tokens=200\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Classify Text  \n",
        "#### Challenge  \n",
        "추론 시간에 제공된 범주로 항목을 분류하십시오. 다음 예에서는 프롬프트에서 분류 할 범주와 텍스트를 모두 제공합니다 (*Playground_reference).\n",
        "\n",
        "고객 문의 : 안녕하세요, 최근 노트북 키보드의 열쇠 중 하나가 최근에 파산되었으며 교체가 필요합니다.\n",
        "\n",
        "분류 카테고리 :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1674499424645
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Classify the following inquiry into one of the following:\n",
        "\n",
        "categories: [Pricing, Hardware Support, Software Support]\n",
        "\n",
        "inquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement.\n",
        "\n",
        "Classified category:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1674499378518
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category: Hardware Support\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=deployment_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful  assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt},\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=60\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Generate New Product Names\n",
        "#### Challenge\n",
        "예제 단어에서 제품 이름을 만듭니다.여기에는 이름을 생성 할 제품에 대한 프롬프트 정보가 포함되어 있습니다.우리는 또한 우리가 받고자하는 패턴을 보여주는 비슷한 예를 제공합니다.또한 임의성과보다 혁신적인 반응을 높이기 위해 온도 값을 높게 설정했습니다.\n",
        "\n",
        "제품 설명 : 홈 밀크 쉐이크 제조업체\n",
        "종자 단어 : 빠르고 건강하며 소형.\n",
        "제품 이름 : Homeshaker, Fit Shaker, Quickshake, Shake Maker\n",
        "\n",
        "제품 설명 : 발 크기에 맞는 신발 한 쌍.\n",
        "종자 단어 : 적응성, 적합, 옴니 피트."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1674257087279
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Product description: A home milkshake maker\n",
        "Seed words: fast, healthy, compact.\n",
        "Product names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
        "\n",
        "Product description: A pair of shoes that can fit any foot size.\n",
        "Seed words: adaptable, fit, omni-fit.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Product names: OneSizeFit, FlexFit, OmniShoe, AdaptiFit\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=deployment_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful  assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt},\n",
        "  ],\n",
        "  temperature=0.8,\n",
        "  max_tokens=60\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Embeddings!  \n",
        "이 섹션에서는 임베딩을 검색하고 단어, 문장 및 문서 사이의 유사성을 찾는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1674829424097
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "text = 'the quick brown fox jumped over the lazy dog'\n",
        "\n",
        "deployment_name = 'text-embedding-ada-002'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1674829446467
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.004474656656384468, 0.00978652760386467, -0.014904950745403767, -0.006424985360354185, -0.01135313231498003, 0.015513833612203598, -0.02372107096016407, -0.016414472833275795, -0.0158182755112648, -0.029632311314344406, 0.021298224106431007, 0.021095262840390205, 0.018570933490991592, 0.004170214757323265, -0.0007155169150792062, -0.007579326163977385, 0.02521790750324726, -0.004214612767100334, 0.011175542138516903, -0.008587788790464401, -0.009513798169791698, 0.021577294915914536, -0.005993693135678768, -0.008257976733148098, 0.006041261833161116, 0.013040246441960335, 0.007439790293574333, -0.0035169341135770082, -0.008955655619502068, 0.0011939817341044545, 0.00666600139811635, 0.0038657733239233494, -0.039272960275411606, -0.002559211803600192, -0.012761174701154232, -0.0217422004789114, -0.0037072100676596165, -0.010458835400640965, 0.02597901225090027, -0.0456916019320488, 0.009399632923305035, 0.015653369948267937, -0.02261747047305107, -0.01161951944231987, -0.0028573106974363327, 0.012215716764330864, 0.010534945875406265, -0.01253284327685833, -0.0228965412825346, 0.01036369800567627, -0.00026955761131830513, 0.006583548616617918, -0.009919720701873302, -0.011625861749053001, -0.004718843847513199, -0.0072368294931948185, -0.0013802936300635338, -0.006250565405935049, 0.009380605071783066, -0.0057621905580163, 0.010782305151224136, 0.013547648675739765, -0.005140622146427631, -0.005632168613374233, 0.0007163097034208477, -0.009399632923305035, 0.011105773970484734, -0.010534945875406265, -0.013052931055426598, -0.004890092182904482, 0.02935323864221573, -0.001888489001430571, 0.00033754162723198533, 0.005996864289045334, 0.0315350703895092, -0.008784406818449497, -0.027450479567050934, 0.00896834023296833, 0.014499028213322163, 0.01159414928406477, 0.029733791947364807, -0.04188608378171921, -0.006066631991416216, 0.0144609734416008, 0.01740390807390213, 0.002544941147789359, -0.025852160528302193, 0.03785223141312599, -0.017036041244864464, 0.011093088425695896, 0.005644853692501783, 0.030748596414923668, 0.008105755783617496, -0.0055275168269872665, -0.017239002510905266, 0.0063901012763381, -0.0008657556609250605, 0.0192305576056242, -0.010046571493148804, -0.025852160528302193, 0.007040210533887148, -0.011714656837284565, -0.027171408757567406, -0.0031125976238399744, 0.006856277119368315, -0.026790855452418327, -0.005492632742971182, 0.022262288257479668, 0.018063532188534737, -0.014219957403838634, 0.01633836328983307, 0.023416629061102867, 0.018203066661953926, -0.039704252034425735, -0.004090933129191399, -0.011308735236525536, 0.009659676812589169, -0.009444030933082104, -0.009266439825296402, -0.008651213720440865, 0.009380605071783066, 0.017657609656453133, 0.02236376889050007, -0.0024339468218386173, -0.01397894136607647, -0.00952014047652483, -0.0038974860217422247, 0.007141691166907549, -0.011308735236525536, 0.0036945249885320663, 0.03249913454055786, 0.023708386346697807, 0.032905057072639465, -0.012437705881893635, -0.03706575930118561, 0.023695699870586395, 0.0051342798396945, -0.011200912296772003, -0.030241193249821663, -0.02241450920701027, -0.001587218721397221, 0.016414472833275795, -0.006577205844223499, 0.008727324195206165, 0.022452564910054207, 0.024088937789201736, 0.02155192382633686, 0.008708296343684196, -0.0020581516437232494, -0.007090950850397348, 0.0181776974350214, -0.0023292950354516506, 0.029860641807317734, 0.0003857052361126989, 0.00962162110954523, 0.015640685334801674, 0.003875287249684334, 0.0144356032833457, -0.027932511642575264, -0.021628035232424736, 0.023683015257120132, 0.022008586674928665, -0.0004213819920551032, -0.008137469179928303, 0.002119991462677717, 0.031154518947005272, 0.03320949897170067, 0.002744730794802308, 0.008035988546907902, -0.010604714043438435, 0.005102567374706268, 0.03298116847872734, -0.011759054847061634, 0.03754778951406479, 0.002018510829657316, 0.006868962198495865, 0.021704144775867462, -0.0078583974391222, -0.03206784278154373, 0.00159118277952075, 0.0040497067384421825, 0.014219957403838634, 0.03881629556417465, 0.0240508820861578, 0.005204047542065382, 0.022541359066963196, 0.005651195999234915, -0.027602700516581535, -0.007344652432948351, -0.0013327245833352208, 0.008733666501939297, 0.0020835218019783497, -0.01879926584661007, -0.01371255423873663, -0.6864141821861267, -0.029860641807317734, 0.004097275901585817, -0.010833045467734337, 0.02160266414284706, 0.0335393100976944, -0.012323539704084396, -0.010446150787174702, -0.00034368596971035004, 0.03544206917285919, -0.03052026592195034, 0.002197687514126301, 0.004687131382524967, -0.0027272887527942657, -0.009824582375586033, -0.00333934323862195, 0.02719677798449993, -0.022972650825977325, -0.007959878072142601, 0.020854245871305466, 0.004791783168911934, 0.006983127910643816, -0.010978923179209232, 0.0017330968985334039, -0.0051342798396945, 0.011296049691736698, -0.0020407098345458508, 0.005349925719201565, -0.001236000913195312, 0.016972616314888, -0.0020359528716653585, 0.018875375390052795, -0.006488410290330648, 0.005441892426460981, 0.04262181743979454, 0.004484170116484165, -0.005946123972535133, 0.020600544288754463, 0.03978036344051361, 0.05337874963879585, -0.03559429198503494, -0.013623759150505066, 0.0145878242328763, 0.008930285461246967, -0.011511695571243763, 0.0011789181735366583, 0.025471609085798264, 0.01716289296746254, -0.0055877710692584515, -0.0156660545617342, 0.013573018833994865, 0.01778445951640606, 0.01635104790329933, 0.00512159476056695, -0.018101586028933525, 0.02704455703496933, 0.010972580872476101, -0.0004316885897424072, -0.0017441964009776711, -0.002383206505328417, -0.010560316033661366, 0.0014667105861008167, -0.0103446701541543, 0.008676583878695965, -0.022579414770007133, 0.0035232766531407833, -0.007046553306281567, 0.010287587530910969, 0.022097382694482803, -0.014321438036859035, 0.0228458009660244, 0.01986481063067913, -0.010553973726928234, 0.01009731087833643, 0.014638564549386501, 0.01080133207142353, 0.009279124438762665, -0.006564520765095949, -0.011581463739275932, 0.006437669973820448, -0.012158634141087532, -0.0026115376967936754, -0.039272960275411606, -0.0015031801303848624, 0.03567039966583252, 0.017200946807861328, -0.03511225804686546, -0.0064027863554656506, -0.005089882295578718, -0.0241523627191782, 0.016845766454935074, 0.024672450497746468, -0.031890250742435455, -0.0011583049781620502, -0.012431363575160503, 0.0085116783156991, -0.006142742466181517, 0.03848648443818092, 0.0411757193505764, -0.03229617327451706, 0.012298169545829296, -0.0018742182292044163, -0.003532790346071124, -0.004239982925355434, 0.014308752492070198, 0.03046952560544014, 0.016756970435380936, 0.0018076216802001, 0.017429279163479805, -0.011156514286994934, -0.008594131097197533, -0.01754344440996647, 0.017467333003878593, 0.00509622460231185, -0.0064598689787089825, -0.02501494623720646, 0.0156660545617342, -0.004465142730623484, 0.015830960124731064, -0.01947157457470894, 0.009425003081560135, -0.011784425005316734, 0.00889222975820303, -0.0008221507305279374, 0.007655436173081398, 0.001875803922303021, -0.026790855452418327, -0.02935323864221573, -0.015919756144285202, -0.004804468248039484, -0.007458817679435015, 0.02024536207318306, 0.03544206917285919, -0.0024339468218386173, -0.0031268682796508074, -0.0043795183300971985, 0.014422918669879436, 0.006161769852042198, 0.01831723377108574, -0.015970496460795403, -0.0316365510225296, 0.009006395936012268, -0.014296067878603935, -0.013611074537038803, 0.007224144414067268, -0.01991555094718933, -0.025826791301369667, 0.004401717334985733, 0.006646973546594381, 0.03052026592195034, -0.012203032150864601, -0.02313755825161934, -0.012367937713861465, -0.015348928049206734, 0.02285848557949066, -0.0053974948823452, -0.03270209580659866, -0.004297065548598766, -0.004645904991775751, -0.02859213575720787, 0.027704181149601936, 0.01402968168258667, -0.0065328083001077175, -0.00420509884133935, 0.01038906816393137, -0.03534058853983879, 0.0032600616104900837, 0.0228965412825346, -0.024596339091658592, -0.026968447491526604, -0.004877407103776932, -0.02260478399693966, -0.006247394252568483, -0.001054445980116725, -0.01755612902343273, 0.011600491590797901, -0.027171408757567406, -0.024266527965664864, -0.002250013407319784, -0.011074061505496502, -0.004347805865108967, 0.018837321549654007, 0.006434498820453882, -0.022769691422581673, 0.015678739175200462, -0.004877407103776932, 0.02468513511121273, 0.012431363575160503, -0.023987457156181335, -0.01007194072008133, 0.021057207137346268, 0.027298258617520332, 0.01277386024594307, -0.013370057567954063, -0.005537030752748251, -0.02019462175667286, 0.0053974948823452, 0.030190452933311462, 0.01494300551712513, 0.009444030933082104, 0.016186142340302467, -0.007541270926594734, 0.007300254423171282, -0.027019187808036804, 0.022021271288394928, -0.03201710432767868, -0.0016078319167718291, -0.004157529678195715, 0.006031747907400131, -0.00013874289288651198, -0.019991662353277206, 0.0004197963571641594, 0.019420834258198738, -0.03871481493115425, 0.017340483143925667, 0.023898661136627197, -0.012298169545829296, 0.02260478399693966, 0.008657556027173996, -0.012843627482652664, 0.002595681231468916, -0.020473694428801537, 0.015285502187907696, -0.005568743217736483, 0.02227497287094593, 0.024672450497746468, 0.008949313312768936, 0.015564573928713799, 0.0016030750703066587, -0.004119474906474352, -0.023505425080657005, 0.003209321293979883, 0.0170740969479084, 0.017036041244864464, 0.008479965850710869, 0.000265197129920125, 0.0073763648979365826, -0.0108203599229455, 0.014714675024151802, -0.0013795007253065705, 0.018063532188534737, -0.006894332356750965, 0.007763259578496218, -0.014016996137797832, 0.011638546362519264, 0.011600491590797901, 0.029327869415283203, -0.005432378966361284, -0.017226317897439003, 0.006463040132075548, -0.0017441964009776711, -0.0035137629602104425, -0.024456804618239403, 0.02767881006002426, 0.007433447986841202, -0.015120596624910831, 0.020955726504325867, 0.005080368369817734, 0.029251758009195328, 0.025141797959804535, 0.004027507733553648, 0.003006360260769725, 0.00889222975820303, 0.01033832784742117, 0.018685100600123405, -0.0005585392354987562, -0.006405957508832216, 0.013116356916725636, 0.013179781846702099, -0.020308788865804672, -0.02564920112490654, -0.005530687980353832, 0.002032781485468149, -0.01754344440996647, 0.020524434745311737, 0.012989506125450134, -0.035315219312906265, 0.013623759150505066, 0.01869778521358967, 0.020334158092737198, -0.021678775548934937, -0.027399739250540733, -0.006104687228798866, 0.004135331138968468, 0.0038372320123016834, 0.005194534081965685, -0.027932511642575264, -0.0003151445707771927, -0.003237862605601549, 0.022287657484412193, -0.00013160755042918026, -0.004766413010656834, 8.805218385532498e-05, -0.00954551063477993, -0.0090127382427454, -0.013446168042719364, 0.020042402669787407, -0.011207254603505135, 0.000565278169233352, -0.028516024351119995, 0.00834042951464653, -0.0005803416715934873, -0.0072621991857886314, -0.007370022591203451, 0.026308823376893997, -0.0006679479265585542, -0.012964135967195034, -0.0011043933918699622, -0.0009379019611515105, 0.019205188378691673, -0.019788701087236404, -0.01402968168258667, -0.017378538846969604, 0.013573018833994865, 0.0025211565662175417, -0.008955655619502068, -0.020017031580209732, -0.011315077543258667, 0.028186213225126266, 0.010084626264870167, -0.013052931055426598, -0.01628762297332287, -0.00637741619721055, 0.02265552431344986, 0.08037257194519043, 0.020740080624818802, -0.018494823947548866, 0.0133827431127429, 0.019116392359137535, -0.026968447491526604, -0.022769691422581673, -0.00637741619721055, 0.027983251959085464, -0.0181269571185112, -0.003780149156227708, -0.009342550300061703, 0.005977836437523365, -0.007890109904110432, 0.024025512859225273, -0.0073763648979365826, 0.0037420939188450575, -0.008448252454400063, 0.002061323029920459, 0.0016300308052450418, -0.005407008808106184, -0.003770635463297367, 0.0002251598925795406, 0.012190346606075764, -0.014207271859049797, 0.0039799390360713005, -0.002403819700703025, 0.016858451068401337, 0.02816084213554859, -0.029632311314344406, -0.0031649235170334578, 0.0075349281542003155, 0.015780219808220863, 0.006272764410823584, 0.021095262840390205, 0.020524434745311737, -0.005191362462937832, 0.014511713758111, 0.032955799251794815, -0.03166192024946213, 0.011797109618782997, 0.007496872916817665, 0.004591993521898985, 0.004842523485422134, 0.023936716839671135, 0.00018294241453986615, -0.01769566535949707, 0.016566693782806396, 0.005981008056551218, -0.029708420857787132, 0.0364568755030632, -0.005235760472714901, -0.010458835400640965, 0.0021723173558712006, 0.0058985548093914986, 0.02554772049188614, -0.019446203485131264, -0.004338291939347982, -0.012964135967195034, 0.0016744284657761455, -0.01036369800567627, -0.020131196826696396, -0.002717775059863925, -0.009507455863058567, -0.001725168782286346, -0.025484293699264526, -0.011740026995539665, -0.008492650464177132, -0.006837249733507633, -0.01501911599189043, -0.02165340445935726, -0.018291862681508064, -0.01890074647963047, -0.010433465242385864, 0.015082541853189468, 0.030444154515862465, 0.010325642302632332, -0.0013271748321130872, 0.004636391066014767, 0.010579343885183334, -0.016858451068401337, -0.01605929248034954, -0.0008498993120156229, -0.026156602427363396, 0.0026384934317320585, 0.009773842059075832, 0.013725239783525467, -0.006478896830230951, 0.0120254410430789, 0.01193030271679163, 0.010579343885183334, 0.008657556027173996, -0.010573001578450203, 0.005739991553127766, 0.02256673015654087, -0.01072522159665823, 0.01195567287504673, 0.03455411642789841, 0.019078336656093597, -0.0053974948823452, 0.03318412974476814, -0.016756970435380936, 0.0008776478935033083, 8.19574052002281e-05, 0.014511713758111, -0.007553956005722284, 0.029962122440338135, 0.005058169364929199, -0.020321473479270935, -0.033285610377788544, 0.03171266242861748, -0.0057621905580163, 0.014866895973682404, 0.012526500970125198, 0.011004293337464333, 0.015069856308400631, 0.015589944086968899, 0.011238967068493366, -0.0001285353791899979, -0.009767499752342701, -0.008467280305922031, -0.021374333649873734, -0.000982299679890275, 0.02935323864221573, -0.025484293699264526, 0.021387018263339996, -0.004198756534606218, -0.015513833612203598, -0.003520105266943574, 0.0032077357172966003, 0.011720999144017696, 0.007370022591203451, 0.0016379589214920998, -0.009780184365808964, -0.04183534160256386, -0.011238967068493366, -0.0036723262164741755, 0.012456733733415604, -0.013509593904018402, 0.0011694043641909957, -0.03095155768096447, -0.008746352046728134, 0.012431363575160503, -0.04285014793276787, 0.019902866333723068, -0.025636514648795128, -0.0015420281561091542, -0.014118476770818233, -0.0023039248771965504, 0.01402968168258667, -0.015780219808220863, -0.010503233410418034, -0.024609025567770004, -0.015792904421687126, -0.002170731546357274, -0.03572114184498787, 0.0079091377556324, -0.015894385054707527, 0.040516097098588943, 0.0180254764854908, 0.03008897230029106, -0.003612072207033634, 0.004699816461652517, 0.024380693212151527, -0.026816226541996002, -0.0038435745518654585, -0.0016680859262123704, -0.0030158739537000656, -0.016427159309387207, -0.0071036359295248985, 0.029632311314344406, 0.005581428296864033, 0.026587894186377525, 0.018811950460076332, -0.01750538870692253, 0.011137486435472965, -0.003894314868375659, 0.008911257609724998, -0.012203032150864601, -0.016173457726836205, 0.020080456510186195, -0.0058287871070206165, 0.016224198043346405, -0.00724317179992795, -0.008689269423484802, -0.0042082699947059155, 0.010465177707374096, 0.03249913454055786, 0.03726872056722641, 0.006450355052947998, 0.022186176851391792, 0.0006576413288712502, -0.004956688731908798, 0.0048139821738004684, -0.003409111173823476, -0.02694307640194893, -0.0016744284657761455, 0.01082670222967863, 0.0063139908015728, 0.026968447491526604, -0.0011440342059358954, 0.016135402023792267, -0.012919737957417965, 0.024190418422222137, -0.003805519314482808, 0.005419693887233734, -0.0115243811160326, -0.011974700726568699, -0.001221730257384479, -0.025864847004413605, -0.010515918023884296, -0.034833185374736786, -0.0113975303247571, -0.017137521877884865, 0.006215681787580252, 0.01957305520772934, -0.011689286679029465, 0.010541288182139397, -0.014714675024151802, -0.037623900920152664, -0.004607849754393101, 0.001599110895767808, 0.044955868273973465, -0.010408095084130764, 0.007902795448899269, 0.012012756429612637, -0.004401717334985733, 0.0011884319828823209, 0.016262251883745193, 0.012437705881893635, 0.004867893643677235, -0.0006806330056861043, 0.018114272505044937, -0.008594131097197533, -0.005032799206674099, -0.01996629126369953, -0.009291809983551502, -0.02439337968826294, -0.010687166824936867, 0.02795788273215294, 0.0008011410827748477, 0.00036429919418878853, -0.008682926185429096, -0.017657609656453133, -0.0003391272621229291, 0.011232624761760235, -0.015171336941421032, -0.006111030001193285, -0.024621710181236267, -4.697437907452695e-05, -0.04183534160256386, 0.009412317536771297, -0.018964171409606934, 0.0034598512575030327, -0.030621744692325592, -0.01260895375162363, 0.007395392749458551, 0.015323557890951633, -0.027704181149601936, -0.006507438141852617, -0.01874852553009987, 0.012805572710931301, -0.025129113346338272, -0.002119991462677717, 0.013408113270998001, 0.002923907246440649, -0.021945161744952202, -0.019978975877165794, -0.005933438893407583, 0.025332072749733925, -0.014042366296052933, -0.01635104790329933, -0.0061300573870539665, 0.012602611444890499, 0.016947245225310326, -0.019776014611124992, 0.00030107208294793963, -0.028718985617160797, -0.005004257895052433, 0.015577259473502636, 0.021539239212870598, -0.001147205475717783, -0.004157529678195715, 0.00729391211643815, -0.009583566337823868, 0.0025306702591478825, 0.003922855947166681, -0.014016996137797832, 0.009919720701873302, -0.019370093941688538, -0.0006207753322087228, -0.016909191384911537, -0.0015380640979856253, 0.003497906494885683, 0.020904986187815666, 0.00032624401501379907, -0.006970442831516266, 0.024368008598685265, -0.02843991480767727, 0.017480019479990005, -0.030723225325345993, 0.006095173303037882, -0.02502763271331787, 0.007813999429345131, 0.010509575717151165, 0.006463040132075548, 0.01405505184084177, -0.020093142986297607, 0.0032568902242928743, -0.025230593979358673, -0.005223075393587351, -0.0036025582812726498, 0.022871172055602074, -0.024862727150321007, 0.011245309375226498, 0.0003555782022885978, 0.010985265485942364, -0.031611181795597076, -0.0079091377556324, 0.033234868198633194, 0.0014722603373229504, 0.024888096377253532, 0.03597484156489372, -0.02434263937175274, 0.007186089176684618, 0.005543373059481382, 0.009488428011536598, 0.012190346606075764, -0.02260478399693966, -0.008048673160374165, -0.009995831176638603, 0.028313063085079193, 0.0039482261054217815, -0.011270679533481598, -0.011600491590797901, -0.0031236971262842417, -0.016465213149785995, 0.015551889315247536, -0.02318829856812954, -0.0029540343675762415, 0.018063532188534737, 0.0026860623620450497, -0.026486415416002274, 0.011010635644197464, -0.013293947093188763, -0.012298169545829296, -0.013192467391490936, -0.005067683290690184, -0.030215824022889137, -0.01967453584074974, -0.0076364087872207165, 0.0023784495424479246, 0.01373792439699173, -0.01164488960057497, -0.025573089718818665, -0.008727324195206165, -0.007002155762165785, -0.010395410470664501, 0.026410304009914398, 0.0037008675280958414, 0.021107947453856468, -0.0228458009660244, 0.011340447701513767, 0.013890145346522331, -0.012976820580661297, 0.030444154515862465, -0.0127040920779109, -0.009558196179568768, -0.006440841592848301, -0.002129505155608058, -0.0023261236492544413, -0.0010695095406845212, -0.004468313883990049, -0.0108964703977108, 0.004598335828632116, 0.021526554599404335, 0.010833045467734337, 0.011238967068493366, -0.008714639581739902, -0.0001291299849981442, -0.004224126227200031, -0.019116392359137535, 0.007579326163977385, -0.008524362929165363, 0.011175542138516903, -0.0267654862254858, -0.011359475553035736, 0.006513780448585749, -0.011974700726568699, -0.026410304009914398, -0.005882698576897383, 0.017873255535960197, -0.005765361711382866, 0.00962162110954523, -0.022300343960523605, -0.0049249762669205666, -0.010985265485942364, -0.02945471927523613, 0.01397894136607647, -0.013002190738916397, 0.029530830681324005, 0.024723190814256668, -0.011695628985762596, -0.010186106897890568, 0.0007638787501491606, 0.0013168682344257832, -0.013623759150505066, -0.021513869985938072, 0.007129006087779999, -0.016997985541820526, -0.0012264872202649713, -0.02950545959174633, 0.001980455592274666, -0.0230995025485754, 0.006710398942232132, -0.022021271288394928, -0.01515865232795477, -0.01740390807390213, 0.024723190814256668, -0.0084609379991889, -0.02117137238383293, -0.0020851073786616325, -0.022287657484412193, 0.003605729667469859, -0.0010718879057094455, -0.0101924492046237, 0.006742111872881651, 0.003875287249684334, -0.01779714599251747, -0.006526465527713299, -0.00012070631782989949, -0.023302463814616203, -0.012818257324397564, 0.015348928049206734, -0.007027525920420885, 0.02208469808101654, 0.20864394307136536, -0.001875803922303021, 0.005407008808106184, 0.036862798035144806, -0.010592028498649597, 0.030139712616801262, 0.021767569705843925, -0.0037262376863509417, -0.006472554057836533, 0.02578873559832573, -0.0026051951572299004, 0.012907053343951702, -0.021615350618958473, 0.005200876388698816, 0.014854210428893566, 0.008467280305922031, -0.005445064045488834, -0.0027685153763741255, -0.014410233125090599, -0.03031730465590954, -0.014473658986389637, -0.006310819648206234, -0.026841595768928528, -0.004344634711742401, 0.010883784852921963, 0.0192812979221344, -0.0085116783156991, -0.0008475208887830377, 0.03267672657966614, 0.018342602998018265, -0.017391223460435867, -0.0027986422646790743, -0.0115243811160326, 0.02255404368042946, -0.014714675024151802, 0.0078583974391222, 0.016274938359856606, 0.018215753138065338, 0.012399650178849697, -0.003875287249684334, 0.0206893403083086, 0.0012185589876025915, -0.0075666410848498344, -0.015107912011444569, 0.0019408148946240544, 0.0253574438393116, 0.017277058213949203, 0.0008839904330670834, -0.012057153508067131, 0.028236953541636467, -0.033437829464673996, 0.0010005345102399588, 0.011670258827507496, 0.030596375465393066, -0.002589338691905141, 0.014816155657172203, 0.02308681793510914, 0.005530687980353832, 0.013167097233235836, 0.01161951944231987, 0.005752676632255316, 0.03518836945295334, -0.028262322768568993, 0.002362593309953809, -0.008740009739995003, 0.010693509131669998, -0.01094086840748787, 0.003827718086540699, -0.008302374742925167, 0.005368953570723534, -0.00952014047652483, -0.005876356270164251, -0.001498423283919692, 0.005603627301752567, -0.0038721158634871244, -0.03224543482065201, 0.0127040920779109, 0.011771739460527897, 0.006621603854000568, 0.018520193174481392, -0.020181937143206596, 0.01624956727027893, -0.0078583974391222, -0.020714709535241127, -0.014638564549386501, -0.01635104790329933, 0.009951433166861534, -0.005112080834805965, -0.030824705958366394, 0.007148033939301968, 0.00019691580382641405, -0.03239765390753746, 0.004427087493240833, -0.003003189107403159, -0.00020573589426930994, 0.0015015945537015796, 0.010909155011177063, 0.02843991480767727, -0.002137433271855116, -0.0091395890340209, -0.0314335897564888, -0.053733933717012405, 0.0085116783156991, 0.004376347176730633, 0.011790767312049866, -0.009995831176638603, 0.005733649246394634, -0.0030555150005966425, 0.0014730531256645918, -0.01067448128014803, -0.004214612767100334, 0.005445064045488834, 0.003751607844606042, 0.0069641005247831345, 0.011384845711290836, -0.007782286964356899, -0.002858896506950259, -0.019446203485131264, -0.009501113556325436, -0.004265353083610535, 0.007052895613014698, -0.0252559632062912, -0.022820431739091873, 0.01164488960057497, -0.0032600616104900837, -0.020372213795781136, 0.004220955073833466, 0.01187956240028143, -0.011765397153794765, -0.036862798035144806, 0.016756970435380936, -0.019116392359137535, 0.011638546362519264, -0.0005367367994040251, -0.006767482031136751, 0.004991572815924883, -0.010744249448180199, -0.014308752492070198, 0.007109978701919317, 0.01846945472061634, 0.010033885948359966, 0.0068055372685194016, -0.010585686191916466, 0.01633836328983307, 0.010553973726928234, -0.03229617327451706, 0.022972650825977325, -0.009361577220261097, -0.023403944447636604, -0.01774640567600727, -0.02126016840338707, 0.00454442435875535, -0.005600456148386002, -0.0008142225560732186, 0.03582262247800827, -0.03737020120024681, -0.023124871775507927, -0.028287693858146667, 0.007902795448899269, 0.0133573729544878, -0.04031313583254814, -0.007991590537130833, 0.004097275901585817, -0.008023303002119064, -0.014410233125090599, -0.019699905067682266, -0.16145549714565277, -0.005099395755678415, 0.014194587245583534, 0.01017342135310173, -0.005368953570723534, -0.011841507628560066, 0.04853305593132973, -0.01657937839627266, -0.026435675099492073, -0.006333018187433481, 0.009602594189345837, 0.0013287605252116919, -0.04325607046484947, 0.0011242137989029288, -0.017277058213949203, 0.0037040389142930508, -0.03036804497241974, 0.013966255821287632, 0.013991625979542732, 0.0020692511461675167, 0.0126787219196558, -0.007585668470710516, 0.022630155086517334, -0.005654367618262768, 0.0031379677820950747, 0.022883856669068336, -0.009044450707733631, 0.009907035157084465, -0.005248445551842451, -0.018647044897079468, -0.02554772049188614, -0.012888025492429733, -0.003336171852424741, -0.01400431152433157, 0.0038911434821784496, 0.0064915819093585014, -0.008873202838003635, 1.66491463460261e-05, -0.0193320382386446, 0.030241193249821663, 0.024241158738732338, 0.045437902212142944, 0.02983527071774006, 0.009951433166861534, -0.004630048293620348, 0.008638529106974602, -0.0009973632404580712, 0.01726437360048294, 0.003608900820836425, -0.0011202497407793999, -0.017150206491351128, -0.012114236131310463, 0.022528674453496933, -0.006786509416997433, 0.0063393609598279, 0.0014072493650019169, -0.005451406352221966, 0.015374298207461834, -0.010579343885183334, 0.00826431903988123, -0.019370093941688538, -0.02752658911049366, 0.005251616705209017, 0.0035169341135770082, -0.037826862186193466, -0.01376329455524683, -0.023416629061102867, 0.02618197351694107, -0.0341481938958168, -0.0114482706412673, -0.006342532113194466, -0.007319282274693251, 0.008042330853641033, 0.008099413476884365, -0.005318213254213333, 0.010668138973414898, -0.01754344440996647, 0.0022959967609494925, 0.0009228384587913752, 0.001937643624842167, -0.005511660594493151, 0.014410233125090599, 0.0001765007764333859, -0.0033932547084987164, 0.006938730366528034, -0.003650127211585641, 0.0015008016489446163, -0.00032961348188109696, 0.0014793956652283669, 0.008143811486661434, -0.005150136072188616, -0.05033433437347412, -0.0030967413913458586, -0.017150206491351128, 0.004997915588319302, 0.02468513511121273, 0.012228402309119701, 0.005622654687613249, 0.002164389006793499, 0.0079091377556324, -0.023302463814616203, -0.014283382333815098, -0.024913467466831207, 0.002540184184908867, 0.00860681664198637, 0.010534945875406265, 0.01919250190258026, 0.012647009454667568, 0.02401282638311386, -0.00045904077705927193, -0.008378485217690468, 0.025522349402308464, 0.008885887451469898, 0.0289726871997118, -0.0030983269680291414, -0.00015618486213497818, 0.007059238385409117, -0.003662812290713191, 0.0001224901498062536, -0.0006433706148527563, 0.0677889809012413, 0.006577205844223499, -0.02492615208029747, -0.0042082699947059155, -0.007154376246035099, 0.02583947591483593, -0.1060471385717392, -0.03095155768096447, 0.010477863252162933, 0.0072812270373106, -0.011143828742206097, 0.02077813632786274, -0.004902777262032032, 0.0017568814801052213, 0.0037833205424249172, 0.02811010368168354, 0.011257994920015335, 0.00016797799617052078, 0.005340412259101868, -0.027120668441057205, 0.03315875679254532, 0.005812930874526501, 0.027780290693044662, -0.006333018187433481, -0.0193827785551548, 0.0193827785551548, -0.005575085990130901, 0.003160166786983609, 0.0015158652095124125, -0.022833116352558136, -0.022934596985578537, -0.005391152575612068, -0.028566764667630196, 0.010135366581380367, -0.0014326194068416953, -0.0039482261054217815, 0.01381403487175703, -0.012184004299342632, 0.003272746689617634, -0.002682891208678484, 0.013192467391490936, 0.016173457726836205, -9.736778156366199e-05, -0.001023526187054813, 0.013509593904018402, -0.012926080264151096, 0.0035708455834537745, 0.006843592040240765, 0.008105755783617496, -0.016642805188894272, 0.02805936336517334, -0.0066025760024785995, 0.016274938359856606, 0.014955691061913967, -0.004322435706853867, -0.003900657407939434, -0.023391257971525192, 0.00136205879971385, -0.02237645350396633, -0.016186142340302467, 0.03972962126135826, 0.006120543461292982, 0.012190346606075764, 0.023898661136627197, 0.008759036660194397, 0.0254081841558218, 0.020537119358778, -0.013560334220528603, -0.0036152433604002, 0.033919863402843475, 0.0289726871997118, -0.002327709225937724, -0.024101622402668, -0.00425583915784955, 0.004572965670377016, -0.003450337564572692, -0.023683015257120132, 0.032955799251794815, -0.014384862966835499, 0.022300343960523605, -0.01067448128014803, -0.0015190364792943, -0.006837249733507633, -0.04140404984354973, 0.015539203770458698, -0.011556093581020832, -0.02256673015654087, -0.02241450920701027, -0.0006984713836573064, -0.02449486032128334, 0.0314335897564888, 0.007300254423171282, -0.008346772752702236, 0.019496943801641464, -0.004836180713027716, 0.0061998250894248486, 0.007668121252208948, 0.009152273647487164, 0.015513833612203598, -0.04812713339924812, -0.024368008598685265, 0.013636444695293903, 0.003210906870663166, -0.006545493379235268, -0.0018472624942660332, 0.021374333649873734, -0.014600508846342564, -0.020562488585710526, -0.021526554599404335, 0.016236882656812668, -0.02275700494647026, -0.014296067878603935, 0.017365852370858192, 0.02193247713148594, -0.016617434099316597, -0.022427193820476532, -0.012888025492429733, -0.008207236416637897, -0.015881700441241264, 0.009196671657264233, -0.020651284605264664, 0.005784389562904835, 0.008486308157444, -0.02367033064365387, -0.0035835306625813246, -0.009380605071783066, 0.002348322654142976, 0.006824564654380083, 0.019699905067682266, 0.001013219472952187, 0.02554772049188614, -0.0007999519002623856, -0.01137850247323513, 0.0019487430108711123, -0.006006378214806318, 0.013915515504777431, -0.029962122440338135, -0.012672379612922668, -0.004867893643677235, -0.03600021451711655, 0.004173386376351118, 0.017378538846969604, 0.0034313099458813667, -0.015615314245223999, 0.004655418451875448, -0.005479947663843632, 0.002862067660316825, 0.01981407031416893, -0.00661526108160615, -0.024355323985219002, 0.005537030752748251, -0.03503614664077759, -0.031940992921590805, 0.003291774308308959, -0.0028715813532471657, 0.00632667588070035, 0.0242031030356884, 0.00022714193619322032, 0.019293982535600662, 0.016325678676366806, -0.01069985143840313, -0.015336242504417896, -0.0031379677820950747, -0.033336348831653595, 0.009526483714580536, -0.005638510920107365, -0.0009172887075692415, -0.032905057072639465, 0.012837285175919533, -0.0029825756791979074, 0.007820342667400837, 0.020181937143206596, 0.015754850581288338, -0.0030158739537000656, 0.0017267543589696288, -0.024913467466831207, 0.013040246441960335, -0.026308823376893997, -0.01501911599189043, 0.020841561257839203, -0.0030697856564074755, 0.0035423042718321085, 0.00546092027798295, 0.0026860623620450497, -0.004125817213207483, 0.0017759089823812246, -0.020042402669787407, 0.006723084021359682, 0.02478661574423313, -0.012260114774107933, -0.006818222347646952, 0.019839441403746605, 0.016110030934214592, 0.00632667588070035, -0.020765449851751328, -0.017606869339942932, -0.0008839904330670834, 0.023074131458997726, -0.00836579967290163, -0.005606798455119133, -0.006393272429704666, 0.003497906494885683, -0.011873220093548298, 0.0019328866619616747, -0.02448217384517193, 0.0115243811160326, -0.003998966421931982, 0.01376329455524683, 0.003066614270210266, 0.00035835307789966464, -0.010902812704443932, -0.031179888173937798, 0.00025627794093452394, 0.005051827058196068, -0.006976785603910685, -0.022186176851391792, -0.001760052633471787, 0.00044833775609731674, -0.00023962878913152963, -0.016503268852829933, -0.010167079046368599, 0.0132558923214674, -0.004731528926640749, 0.03079933673143387, 0.0037325802259147167, -0.014296067878603935, -0.0315350703895092, 0.03346319869160652, 0.01957305520772934, -0.005375295877456665, 0.02067665569484234, -0.006396443583071232, 0.01706141233444214, 0.005381638649851084, 0.011505353264510632, -0.031230628490447998, -0.029429350048303604, 0.008010618388652802, -0.003973596263676882, -0.0012510644737631083, 0.0005874770577065647, 0.0039482261054217815, -0.009900692850351334, -0.02554772049188614, 0.012057153508067131, 0.03802982345223427, -0.008270662277936935, 0.05677834898233414, 0.030291933566331863, -0.016262251883745193, -0.002917564706876874, 0.0031823655590415, 0.013370057567954063, 0.012685064226388931, 0.01605929248034954, -0.036659836769104004, -0.015120596624910831, 0.00959625095129013, -0.007052895613014698, 0.019116392359137535, -0.03057100437581539, -0.017860570922493935, -0.027450479567050934, -0.0314335897564888, -0.009431345388293266, -0.007852055132389069, -0.019940922036767006, 0.025433553382754326, 0.0014738459140062332, 0.005644853692501783, -0.0048139821738004684, -0.018139641731977463, -0.024456804618239403, 0.035847991704940796, 0.0011765396920964122, -0.0020644941832870245, -0.020600544288754463, -0.004125817213207483, -0.0021881735883653164, -0.020461009815335274, -0.014245327562093735, 0.0291249081492424, -0.001054445980116725, 0.016604749485850334, 0.012951450422406197, 0.03181414306163788, -0.005914411507546902, -0.016363732516765594, 0.011778082698583603, -0.013915515504777431, -0.00860681664198637, 0.02613123320043087, 0.039653509855270386, -0.0291249081492424, 0.018583619967103004, -0.04132793843746185]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector = client.embeddings.create(input = [text], model=deployment_name).data[0].embedding\n",
        "print(vector)\n",
        "len(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1674829555255
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The new movie is awesome\tThe dog plays in the garden\tScore: 0.7488\n",
            "The new movie is awesome\tThis recent movie is so good\tScore: 0.9191\n",
            "The new movie is awesome\tThe new movie is awesome\tScore: 1.0000\n"
          ]
        }
      ],
      "source": [
        "sentences1 = ['The new movie is awesome',  \n",
        "              'The new movie is awesome',  \n",
        "              'The new movie is awesome']  \n",
        "  \n",
        "sentences2 = ['The dog plays in the garden',  \n",
        "              'This recent movie is so good',  \n",
        "              'The new movie is awesome']  \n",
        "\n",
        "embeddings1 = [client.embeddings.create(input = s, model=deployment_name).data[0].embedding for s in sentences1]  \n",
        "embeddings2 = [client.embeddings.create(input = s, model=deployment_name).data[0].embedding for s in sentences2]  \n",
        "  \n",
        "for i in range(len(sentences1)):  \n",
        "    print(\"{}\\t{}\\tScore: {:.4f}\".format(sentences1[i], sentences2[i], cosine_similarity(embeddings1[i], embeddings2[i])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "바나나 우유는 목욕 후에 마시면 더 맛있습니다.\t바나나 우유는 목욕 후에 마시면 더 맛있습니다.\tScore: 1.0000\n",
            "바나나 우유는 목욕 후에 마시면 더 맛있습니다.\t목욕 후에 바나나 우유를 마시면 더 맛있습니다.\tScore: 0.9728\n",
            "바나나 우유는 목욕 후에 마시면 더 맛있습니다.\t딸기 우유는 목욕 전에 마시면 더 맛있습니다.\tScore: 0.9264\n",
            "바나나 우유는 목욕 후에 마시면 더 맛있습니다.\t우유는 시리얼이랑 먹으면 더 고소한 맛이 납니다.\tScore: 0.8722\n",
            "바나나 우유는 목욕 후에 마시면 더 맛있습니다.\t어제는 비랑 눈이 와서 날씨가 더 추웠습니다.\tScore: 0.7893\n",
            "바나나 우유는 목욕 후에 마시면 더 맛있습니다.\t다가오는 2024 OpenAI DevDay는 직관할 수 있을까?\tScore: 0.7250\n",
            "바나나 우유는 목욕 후에 마시면 더 맛있습니다.\tABCDE FGHI JKL MNO PQR STU VWXYZ ABCDEFG\tScore: 0.6964\n"
          ]
        }
      ],
      "source": [
        "sentences1 = [\n",
        "              '바나나 우유는 목욕 후에 마시면 더 맛있습니다.',  \n",
        "              '바나나 우유는 목욕 후에 마시면 더 맛있습니다.',  \n",
        "              '바나나 우유는 목욕 후에 마시면 더 맛있습니다.',  \n",
        "              '바나나 우유는 목욕 후에 마시면 더 맛있습니다.',  \n",
        "              '바나나 우유는 목욕 후에 마시면 더 맛있습니다.',  \n",
        "              '바나나 우유는 목욕 후에 마시면 더 맛있습니다.',  \n",
        "              '바나나 우유는 목욕 후에 마시면 더 맛있습니다.',  \n",
        "            ]\n",
        "  \n",
        "sentences2 = [\n",
        "              '바나나 우유는 목욕 후에 마시면 더 맛있습니다.',  \n",
        "              '목욕 후에 바나나 우유를 마시면 더 맛있습니다.',\n",
        "              '딸기 우유는 목욕 전에 마시면 더 맛있습니다.',  \n",
        "              '우유는 시리얼이랑 먹으면 더 고소한 맛이 납니다.',\n",
        "              '어제는 비랑 눈이 와서 날씨가 더 추웠습니다.',\n",
        "              '다가오는 2024 OpenAI DevDay는 직관할 수 있을까?',\n",
        "              'ABCDE FGHI JKL MNO PQR STU VWXYZ ABCDEFG',\n",
        "            ]\n",
        "\n",
        "embeddings1 = [client.embeddings.create(input = s, model=deployment_name).data[0].embedding for s in sentences1]  \n",
        "embeddings2 = [client.embeddings.create(input = s, model=deployment_name).data[0].embedding for s in sentences2]  \n",
        "  \n",
        "for i in range(len(sentences1)):  \n",
        "    print(\"{}\\t{}\\tScore: {:.4f}\".format(sentences1[i], sentences2[i], cosine_similarity(embeddings1[i], embeddings2[i])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Contributors\n",
        "Louis Li"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 궁금증 있을 때 연락 주세요.  \n",
        "Prompt Engineering과 관련 궁금증이 있을 경우 아래 이메일로 요청 주세요.  \n",
        "MS Korea 김현수 이메일: [<hyounsookim@microsoft.com>](hyounsookim@microsoft.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
